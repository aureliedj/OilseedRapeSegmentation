{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as T\n",
    "\n",
    "T_norm = T.Compose([\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "T_tensor = T.Compose([\n",
    "    T.ToTensor()\n",
    "])\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def getPredict(a):\n",
    "    pred =a['out'].data.cpu().numpy()\n",
    "    return np.argmax(pred, axis=1)[0]\n",
    "\n",
    "def get_segment_labels(image, model, device, transform):\n",
    "    # transform the image to tensor and load into computation device\n",
    "    image = transform(image).to(device)\n",
    "    image = image.unsqueeze(0) # add a batch dimension\n",
    "    outputs = model(image)\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "num_class = 2\n",
    "confusion_matrix = np.zeros((num_class,)*2)\n",
    "\n",
    "def Pixel_Accuracy(confusion_matrix):\n",
    "    Acc = np.diag(confusion_matrix).sum() / confusion_matrix.sum()\n",
    "    return Acc\n",
    "\n",
    "def Pixel_Accuracy_Class(confusion_matrix):\n",
    "    Acc = np.diag(confusion_matrix) / confusion_matrix.sum(axis=1)\n",
    "    #Acc = np.nanmean(Acc)\n",
    "    return Acc\n",
    "\n",
    "def Mean_Intersection_over_Union(confusion_matrix):\n",
    "    MIoU = np.diag(confusion_matrix) / (\n",
    "                np.sum(confusion_matrix, axis=1) + np.sum(confusion_matrix, axis=0) -\n",
    "                np.diag(confusion_matrix))\n",
    "    MIoU = np.nanmean(MIoU)\n",
    "    return MIoU\n",
    "\n",
    "def Frequency_Weighted_Intersection_over_Union(confusion_matrix):\n",
    "    freq = np.sum(confusion_matrix, axis=1) / np.sum(confusion_matrix)\n",
    "    iu = np.diag(confusion_matrix) / (\n",
    "                np.sum(confusion_matrix, axis=1) + np.sum(confusion_matrix, axis=0) -\n",
    "                np.diag(confusion_matrix))\n",
    "\n",
    "    FWIoU = (freq[freq > 0] * iu[freq > 0]).sum()\n",
    "    return FWIoU\n",
    "\n",
    "def _generate_matrix(num_class, gt_image, pre_image):\n",
    "    mask = (gt_image >= 0) & (gt_image < num_class)\n",
    "    label = num_class * gt_image[mask].astype('int') + pre_image[mask]\n",
    "    count = np.bincount(label, minlength=num_class**2)\n",
    "    confusion_matrix = count.reshape(num_class, num_class)\n",
    "    return confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_batch(confusion_matrix, num_class, gt_image, pre_image):\n",
    "    #assert gt_image.shape == pre_image.shape\n",
    "    cm = confusion_matrix + _generate_matrix(num_class, gt_image, pre_image)\n",
    "    return cm\n",
    "\n",
    "def reset(num_class):\n",
    "    return np.zeros((num_class,) * 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPourcentage(a):\n",
    "    return np.sum(a)/(a.shape[0]*a.shape[1])\n",
    "\n",
    "def getGt(gt):\n",
    "    return np.sum(gt)/(gt.shape[0]*gt.shape[1])\n",
    "\n",
    "def getDiff(gt, a):\n",
    "    p_gt = getGt(gt)\n",
    "    diff = p_gt  - getPourcentage(a)\n",
    "    return p_gt, diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_Md = {'180920':500,\n",
    "'180926':586,\n",
    "'181009':747,\n",
    "'181015':828,\n",
    "'181022':903,\n",
    "}\n",
    "\n",
    "dict_Pr = {'180919':579,\n",
    "'180926':696,\n",
    "'181010':895,\n",
    "'181016':989,\n",
    "'181116':1295,\n",
    "'190913':324,\n",
    "'190927':565,\n",
    "'191007':706,\n",
    "'191029':981,\n",
    "'20200916':570,\n",
    "'20200917':570,\n",
    "'20200924':725,\n",
    "'20200930':785,\n",
    "'20201008':873,\n",
    "'20201014':932\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE Loading models...\n"
     ]
    }
   ],
   "source": [
    "# Load the trained model \n",
    "model = torch.load(r'C:\\Users\\A60026184\\Desktop\\ModelA\\Results\\weights_Aaug5_v0.pt')\n",
    "model.eval()\n",
    "\n",
    "print('DONE Loading models...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_files = glob(r'C:\\Users\\A60026184\\Desktop\\ModelA\\Test\\Flowers\\Images\\*.*')\n",
    "msk_path = r'C:\\Users\\A60026184\\Desktop\\ModelA\\Test\\Flowers\\Masks'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = reset(2)\n",
    "\n",
    "for f in img_files:\n",
    "    filename = f.split('\\\\')[-1] #[:8] #Model B full\n",
    "    msk = glob(msk_path+'\\\\'+filename)[0]\n",
    "    \n",
    "    # read the image\n",
    "    image = Image.open(f)\n",
    "    # Read  a sample image and mask from the data-set\n",
    "    mask = np.array(Image.open(msk))\n",
    "    \n",
    "    ### ----------- MODEL A ------------ ###\n",
    "    if len(mask.shape)>2:\n",
    "        mask = mask[:,:,0]\n",
    "    mask[mask<127]=0\n",
    "    mask[mask>0]=1\n",
    "    \n",
    "    result = get_segment_labels(image, model, device, T_norm)\n",
    "    pred = getPredict(result)\n",
    "    \n",
    "    cm += _generate_matrix(2, mask, pred)\n",
    "\n",
    "Acc_a = Pixel_Accuracy(cm)\n",
    "cAcc_a = Pixel_Accuracy_Class(cm)\n",
    "mIoU = Mean_Intersection_over_Union(cm)\n",
    "fwIoU = Frequency_Weighted_Intersection_over_Union(cm)\n",
    "\n",
    "print(' Pixel Accuracy is', round(Acc_a*100,2), '%\\n',\n",
    "      'Class Accuracy \\n', \n",
    "      'Background ', round(cAcc_a[0]*100,2),\n",
    "      '%\\n Vegetation', round(cAcc_a[1]*100,2),\n",
    "      '%\\n mean IoU is', round(mIoU*100,2),\n",
    "      '%\\n frequency weighted IoU is ',round(fwIoU*100,2),'%')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gt = []\n",
    "pred = []\n",
    "dat, loc, adv, mod, rep = [], [], [], [], []\n",
    "\n",
    "for f in img_files:\n",
    "    filename = f.split('\\\\')[-1]\n",
    "    msk = glob(msk_path+'\\\\'+filename)[0]\n",
    "    \n",
    "    filename = filename.split('.')[0]\n",
    "    \n",
    "    dat.append(filename.split('_')[1])\n",
    "    loc.append(filename.split('_')[2])\n",
    "    adv.append(filename.split('_')[3])\n",
    "    mod.append(filename.split('_')[4])\n",
    "    rep.append(filename.split('_')[5])\n",
    "    \n",
    "    # read the image\n",
    "    image = Image.open(f)\n",
    "    # Read  a sample image and mask from the data-set\n",
    "    mask = np.array(Image.open(msk))\n",
    "    if len(mask.shape)>2:\n",
    "        mask = mask[:,:,0]\n",
    "    mask[mask<=127]=0\n",
    "    mask[mask>0]=1\n",
    "    \n",
    "    result = get_segment_labels(image, model, device, T_norm)\n",
    "    predict = getPredict(result)\n",
    "    \n",
    "    gt.append(getGt(mask))\n",
    "    pred.append(getPourcentage(predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-105-72e8136f0f36>:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['DJ'][df['Lieu']=='Md'] = df['Date'][df['Lieu']=='Md'].map(dict_Md)\n",
      "<ipython-input-105-72e8136f0f36>:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['DJ'][df['Lieu']!='Md'] = df['Date'][df['Lieu']!='Md'].map(dict_Pr)\n"
     ]
    }
   ],
   "source": [
    "df_gt = pd.DataFrame(gt,columns = ['Groundtruth'])\n",
    "df_pred = pd.DataFrame(pred, columns= ['Predictions'])\n",
    "\n",
    "abs_err = np.abs(np.array(gt)-np.array(pred))\n",
    "df_err = pd.DataFrame(abs_err, columns=['Abs err'])\n",
    "\n",
    "DJ = np.zeros(np.shape(abs_err))\n",
    "df_DJ = pd.DataFrame(DJ, columns=['DJ'])\n",
    "\n",
    "df_dat = pd.DataFrame(dat, columns=['Date'])\n",
    "df_loc = pd.DataFrame(loc, columns=['Lieu'])\n",
    "df_adv = pd.DataFrame(adv, columns=['Type'])\n",
    "df_mod = pd.DataFrame(mod, columns=['Moda'])\n",
    "df_rep = pd.DataFrame(rep, columns=['Rep'])\n",
    "\n",
    "df = pd.concat([df_dat, df_loc, df_adv, df_mod, df_rep,\n",
    "                df_gt, df_pred, df_err, df_DJ], axis=1)\n",
    "df = df.groupby(['Date', 'Lieu', 'Type', 'Moda', 'Rep']).mean().reset_index()\n",
    "\n",
    "df['DJ'][df['Lieu']=='Md'] = df['Date'][df['Lieu']=='Md'].map(dict_Md)\n",
    "df['DJ'][df['Lieu']!='Md'] = df['Date'][df['Lieu']!='Md'].map(dict_Pr)\n",
    "\n",
    "df.to_csv(r'H:\\Aur√©lie\\ModelEval\\ModelA\\Raw\\flowers_Av0.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
