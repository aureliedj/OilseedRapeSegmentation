{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as T\n",
    "\n",
    "T_norm = T.Compose([\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "T_tensor = T.Compose([\n",
    "    T.ToTensor()\n",
    "])\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def getPredict(a):\n",
    "    pred =a['out'].data.cpu().numpy()\n",
    "    return np.argmax(pred, axis=1)[0]\n",
    "\n",
    "def get_segment_labels(image, model, device, transform):\n",
    "    # transform the image to tensor and load into computation device\n",
    "    image = transform(image).to(device)\n",
    "    image = image.unsqueeze(0) # add a batch dimension\n",
    "    outputs = model(image)\n",
    "    return outputs\n",
    "\n",
    "def getSP(mask):\n",
    "    return np.sum(mask==1)/(mask.shape[0]*mask.shape[1])\n",
    "\n",
    "def getOSR(mask):\n",
    "    return np.sum(mask==2)/(mask.shape[0]*mask.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_class = 3\n",
    "confusion_matrix = np.zeros((num_class,)*2)\n",
    "\n",
    "def Pixel_Accuracy(confusion_matrix):\n",
    "    Acc = np.diag(confusion_matrix).sum() / confusion_matrix.sum()\n",
    "    return Acc\n",
    "\n",
    "def Pixel_Accuracy_Class(confusion_matrix):\n",
    "    Acc = np.diag(confusion_matrix) / confusion_matrix.sum(axis=1)\n",
    "    #Acc = np.nanmean(Acc)\n",
    "    return Acc\n",
    "\n",
    "def Mean_Intersection_over_Union(confusion_matrix):\n",
    "    MIoU = np.diag(confusion_matrix) / (\n",
    "                np.sum(confusion_matrix, axis=1) + np.sum(confusion_matrix, axis=0) -\n",
    "                np.diag(confusion_matrix))\n",
    "    MIoU = np.nanmean(MIoU)\n",
    "    return MIoU\n",
    "\n",
    "def Frequency_Weighted_Intersection_over_Union(confusion_matrix):\n",
    "    freq = np.sum(confusion_matrix, axis=1) / np.sum(confusion_matrix)\n",
    "    iu = np.diag(confusion_matrix) / (\n",
    "                np.sum(confusion_matrix, axis=1) + np.sum(confusion_matrix, axis=0) -\n",
    "                np.diag(confusion_matrix))\n",
    "\n",
    "    FWIoU = (freq[freq > 0] * iu[freq > 0]).sum()\n",
    "    return FWIoU\n",
    "\n",
    "def _generate_matrix(num_class, gt_image, pre_image):\n",
    "    mask = (gt_image >= 0) & (gt_image < num_class)\n",
    "    label = num_class * gt_image[mask].astype('int') + pre_image[mask]\n",
    "    count = np.bincount(label, minlength=num_class**2)\n",
    "    confusion_matrix = count.reshape(num_class, num_class)\n",
    "    return confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_batch(confusion_matrix, num_class, gt_image, pre_image):\n",
    "    #assert gt_image.shape == pre_image.shape\n",
    "    cm = confusion_matrix + _generate_matrix(num_class, gt_image, pre_image)\n",
    "    return cm\n",
    "\n",
    "def reset(num_class):\n",
    "    return np.zeros((num_class,) * 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_Md = {'180920':500,\n",
    "'180926':586,\n",
    "'181009':747,\n",
    "'181015':828,\n",
    "'181022':903,\n",
    "}\n",
    "\n",
    "dict_Pr = {'180919':579,\n",
    "'180926':696,\n",
    "'181010':895,\n",
    "'181016':989,\n",
    "'181116':1295,\n",
    "'190913':324,\n",
    "'190927':565,\n",
    "'191007':706,\n",
    "'191029':981,\n",
    "'20200916':570,\n",
    "'20200917':570,\n",
    "'20200924':725,\n",
    "'20200930':785,\n",
    "'20201008':873,\n",
    "'20201014':932\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE Loading models...\n"
     ]
    }
   ],
   "source": [
    "# Load the trained model \n",
    "model = torch.load(r'C:\\Users\\A60026184\\Desktop\\ModelB\\Results\\weights_cascBaug5_v0.pt')\n",
    "model.eval()\n",
    "\n",
    "print('DONE Loading models...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_files = glob(r'C:\\Users\\A60026184\\Desktop\\ModelB\\Test\\Rapeseed\\ImgMasked\\*.*')\n",
    "msk_path = r'C:\\Users\\A60026184\\Desktop\\ModelB\\Test\\Rapeseed\\Join'\n",
    "pathout = r'H:\\AurÃ©lie\\ModelEval\\ModelB\\Raw\\B1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = reset(3)\n",
    "\n",
    "for f in img_files:\n",
    "    filename = f.split('\\\\')[-1] #[:8] #Model B full\n",
    "    #if filename[0]=='0':\n",
    "    #    filename = filename[1:]\n",
    "    msk = glob(msk_path+'\\\\'+filename)[0]\n",
    "    \n",
    "    # read the image\n",
    "    image = Image.open(f)\n",
    "    # Read  a sample image and mask from the data-set\n",
    "    mask = np.array(Image.open(msk))\n",
    "    \n",
    "    ### ----------- MODEL B ------------ ###\n",
    "    mask[mask < 127] = 0\n",
    "    mask[mask > 127] = 1\n",
    "    mask[mask[:, :, 1] > 0] = 2\n",
    "    mask = mask[:,:,0]\n",
    "    \n",
    "    result = get_segment_labels(image, model, device, T_norm)\n",
    "    pred = getPredict(result)\n",
    "    \n",
    "    cm += _generate_matrix(3, mask, pred)\n",
    "\n",
    "Acc_a = Pixel_Accuracy(cm)\n",
    "cAcc_a = Pixel_Accuracy_Class(cm)\n",
    "mIoU = Mean_Intersection_over_Union(cm)\n",
    "fwIoU = Frequency_Weighted_Intersection_over_Union(cm)\n",
    "\n",
    "print(' Pixel Accuracy is', round(Acc_a*100,2), '%\\n',\n",
    "      'Class Accuracy \\n', \n",
    "      'Background ', round(cAcc_a[0]*100,2),\n",
    "      '%\\n Vegetation', round(cAcc_a[1]*100,2),\n",
    "      ### ----------- MODEL B ------------ ###\n",
    "      '%\\n Oilseed rape', round(cAcc_a[2]*100,2),\n",
    "      '%\\n mean IoU is', round(mIoU*100,2),\n",
    "      '%\\n frequency weighted IoU is ',round(fwIoU*100,2),'%')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "SP_gt = []\n",
    "SP_pred = []\n",
    "OSR_gt = []\n",
    "OSR_pred = []\n",
    "dat, loc, adv, mod, rep = [], [], [], [], []\n",
    "\n",
    "for f in img_files:\n",
    "    \n",
    "    filename = f.split('\\\\')[-1]\n",
    "    #if filename[0]=='0':\n",
    "    #    filename=filename[1:]\n",
    "    msk = glob(msk_path+'\\\\'+filename)[0]\n",
    "    \n",
    "    filename = filename.split('.')[0]\n",
    "    \n",
    "    dat.append(filename.split('_')[1])\n",
    "    loc.append(filename.split('_')[2])\n",
    "    adv.append(filename.split('_')[3])\n",
    "    mod.append(filename.split('_')[4])\n",
    "    rep.append(filename.split('_')[5])\n",
    "    \n",
    "    # read the image\n",
    "    image = Image.open(f)\n",
    "    # Read  a sample image and mask from the data-set\n",
    "    mask = np.array(Image.open(msk))\n",
    "    mask[mask < 127] = 0\n",
    "    mask[mask >= 127] = 1\n",
    "    mask[mask[:, :, 1] > 0] = 2\n",
    "    mask = mask[:,:,0]\n",
    "    \n",
    "    result = get_segment_labels(image, model, device, T_norm)\n",
    "    pred = getPredict(result)  \n",
    "    \n",
    "    SP_gt.append(getSP(mask))\n",
    "    SP_pred.append(getSP(pred))\n",
    "    \n",
    "    OSR_gt.append(getOSR(mask))\n",
    "    OSR_pred.append(getOSR(pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'9_20200916_Ch_A_M02_4'"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-100-5ccab35563f3>:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['DJ'][df['Lieu']=='Md'] = df['Date'][df['Lieu']=='Md'].map(dict_Md)\n",
      "<ipython-input-100-5ccab35563f3>:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['DJ'][df['Lieu']!='Md'] = df['Date'][df['Lieu']!='Md'].map(dict_Pr)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_SPgt = pd.DataFrame(SP_gt,columns = ['Gt SP'])\n",
    "df_OSRgt = pd.DataFrame(OSR_gt,columns = ['Gt OSR'])\n",
    "\n",
    "SP_err = np.abs(np.array(SP_gt)-np.array(SP_pred))\n",
    "OSR_err = np.abs(np.array(OSR_gt)-np.array(OSR_pred))\n",
    "df_SP = pd.DataFrame(SP_err, columns=['SP_err'])\n",
    "df_OSR = pd.DataFrame(OSR_err, columns=['OSR_err'])\n",
    "\n",
    "DJ = np.zeros(np.shape(SP_err))\n",
    "df_DJ = pd.DataFrame(DJ, columns=['DJ'])\n",
    "\n",
    "\n",
    "df_dat = pd.DataFrame(dat, columns=['Date'])\n",
    "df_loc = pd.DataFrame(loc, columns=['Lieu'])\n",
    "df_adv = pd.DataFrame(adv, columns=['Type'])\n",
    "df_mod = pd.DataFrame(mod, columns=['Moda'])\n",
    "df_rep = pd.DataFrame(rep, columns=['Rep'])\n",
    "\n",
    "df = pd.concat([df_dat, df_loc, df_adv, df_mod, df_rep,\n",
    "                df_SPgt, df_SP, df_OSRgt, df_OSR, df_DJ], axis=1)\n",
    "df = df.groupby(['Date', 'Lieu', 'Type', 'Moda', 'Rep']).mean().reset_index()\n",
    "\n",
    "df['DJ'][df['Lieu']=='Md'] = df['Date'][df['Lieu']=='Md'].map(dict_Md)\n",
    "df['DJ'][df['Lieu']!='Md'] = df['Date'][df['Lieu']!='Md'].map(dict_Pr)\n",
    "\n",
    "df.to_csv(pathout + '\\\\rapeseed_Bv0.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
